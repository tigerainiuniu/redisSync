"""
å¢é‡è¿ç§»å¤„ç†å™¨

å®ç°Redisçš„å¢é‡æ•°æ®è¿ç§»ï¼Œæ”¯æŒåŸºäºæ—¶é—´æˆ³ã€é”®å˜æ›´ç›‘æ§å’Œå¤åˆ¶æµçš„å¢é‡åŒæ­¥ã€‚
å¯ä»¥æ£€æµ‹å’ŒåŒæ­¥æºRedisä¸­çš„æ•°æ®å˜æ›´åˆ°ç›®æ ‡Redisã€‚
"""

import redis
import logging
import time
import threading
import json
from typing import Optional, Callable, Dict, Any, List, Set
from datetime import datetime, timedelta
from collections import defaultdict

from .exceptions import MigrationError, ReplicationError
from .utils import ProgressTracker, format_duration

logger = logging.getLogger(__name__)


class IncrementalMigrationHandler:
    """å¤„ç†Rediså¢é‡è¿ç§»çš„æ ¸å¿ƒç±»ã€‚"""

    def __init__(self, source_client: redis.Redis, target_client: redis.Redis, scan_count: int = 10000):
        """
        åˆå§‹åŒ–å¢é‡è¿ç§»å¤„ç†å™¨ã€‚

        å‚æ•°:
            source_client: æºRediså®¢æˆ·ç«¯
            target_client: ç›®æ ‡Rediså®¢æˆ·ç«¯
            scan_count: SCANå‘½ä»¤çš„COUNTå‚æ•°ï¼ˆé»˜è®¤10000ï¼‰
        """
        self.source_client = source_client
        self.target_client = target_client
        self.scan_count = scan_count  # å¯é…ç½®çš„SCAN count
        self.last_sync_time = None
        self.sync_checkpoint = None
        self.is_monitoring = False
        self.monitor_thread = None
        self.stop_event = threading.Event()

        # å¢é‡è¿ç§»ç»Ÿè®¡
        self.incremental_stats = {
            'start_time': None,
            'last_sync_time': None,
            'total_changes': 0,
            'successful_changes': 0,
            'failed_changes': 0,
            'change_types': defaultdict(int),
            'sync_intervals': []
        }
    
    def start_incremental_sync(self,
                              sync_interval: int = 60,
                              key_pattern: str = "*",
                              key_types: Optional[List[str]] = None,
                              change_callback: Optional[Callable] = None,
                              max_changes_per_sync: int = 10000) -> bool:
        """
        å¯åŠ¨å¢é‡åŒæ­¥ã€‚
        
        å‚æ•°:
            sync_interval: åŒæ­¥é—´éš”ï¼ˆç§’ï¼‰
            key_pattern: é”®æ¨¡å¼è¿‡æ»¤
            key_types: é”®ç±»å‹è¿‡æ»¤
            change_callback: å˜æ›´å›è°ƒå‡½æ•°
            max_changes_per_sync: æ¯æ¬¡åŒæ­¥çš„æœ€å¤§å˜æ›´æ•°
            
        è¿”å›:
            æ˜¯å¦æˆåŠŸå¯åŠ¨
        """
        if self.is_monitoring:
            logger.warning("å¢é‡åŒæ­¥å·²åœ¨è¿è¡Œ")
            return False
        
        logger.info(f"å¯åŠ¨å¢é‡åŒæ­¥ï¼Œé—´éš”: {sync_interval}ç§’")
        
        self.incremental_stats['start_time'] = datetime.now()
        self.last_sync_time = time.time()
        self.is_monitoring = True
        self.stop_event.clear()
        
        # å¯åŠ¨ç›‘æ§çº¿ç¨‹
        self.monitor_thread = threading.Thread(
            target=self._incremental_sync_worker,
            args=(sync_interval, key_pattern, key_types, change_callback, max_changes_per_sync),
            daemon=True
        )
        self.monitor_thread.start()
        
        return True
    
    def stop_incremental_sync(self) -> Dict[str, Any]:
        """
        åœæ­¢å¢é‡åŒæ­¥ã€‚
        
        è¿”å›:
            åŒæ­¥ç»Ÿè®¡ä¿¡æ¯
        """
        if not self.is_monitoring:
            logger.warning("å¢é‡åŒæ­¥æœªåœ¨è¿è¡Œ")
            return self.incremental_stats
        
        logger.info("åœæ­¢å¢é‡åŒæ­¥")
        self.stop_event.set()
        self.is_monitoring = False
        
        if self.monitor_thread and self.monitor_thread.is_alive():
            self.monitor_thread.join(timeout=10)
        
        return self.incremental_stats
    
    def perform_incremental_sync(self,
                                key_pattern: str = "*",
                                key_types: Optional[List[str]] = None,
                                since_timestamp: Optional[float] = None,
                                max_changes: int = 10000) -> Dict[str, Any]:
        """
        æ‰§è¡Œä¸€æ¬¡å¢é‡åŒæ­¥ã€‚

        å‚æ•°:
            key_pattern: é”®æ¨¡å¼è¿‡æ»¤
            key_types: é”®ç±»å‹è¿‡æ»¤
            since_timestamp: èµ·å§‹æ—¶é—´æˆ³
            max_changes: æœ€å¤§å˜æ›´æ•°

        è¿”å›:
            åŒæ­¥ç»“æœ
        """
        start_time = time.time()
        sync_timestamp = since_timestamp or self.last_sync_time or start_time

        logger.info("=" * 60)
        logger.info("å¼€å§‹æ‰§è¡Œå¢é‡åŒæ­¥")
        logger.info(f"  é”®æ¨¡å¼: {key_pattern}")
        logger.info(f"  é”®ç±»å‹è¿‡æ»¤: {key_types}")
        logger.info(f"  ä¸Šæ¬¡åŒæ­¥æ—¶é—´: {sync_timestamp} ({time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(sync_timestamp))})")
        logger.info(f"  å½“å‰æ—¶é—´: {start_time} ({time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(start_time))})")
        logger.info(f"  æ—¶é—´å·®: {start_time - sync_timestamp:.2f} ç§’")
        logger.info(f"  æœ€å¤§å˜æ›´æ•°: {max_changes}")

        try:
            # æ£€æµ‹å˜æ›´çš„é”®
            logger.info("å¼€å§‹æ£€æµ‹å˜æ›´çš„é”®...")
            changed_keys = self._detect_changed_keys(
                key_pattern, key_types, sync_timestamp, max_changes
            )

            if not changed_keys:
                logger.info("âœ“ æœªæ£€æµ‹åˆ°é”®å˜æ›´")
                logger.info("=" * 60)
                return {
                    'success': True,
                    'changed_keys': 0,
                    'synced_keys': 0,
                    'failed_keys': 0,
                    'duration': time.time() - start_time
                }

            logger.info(f"âœ“ æ£€æµ‹åˆ° {len(changed_keys)} ä¸ªå˜æ›´çš„é”®:")
            for i, key in enumerate(changed_keys[:10], 1):  # åªæ˜¾ç¤ºå‰10ä¸ª
                logger.info(f"  {i}. {key}")
            if len(changed_keys) > 10:
                logger.info(f"  ... è¿˜æœ‰ {len(changed_keys) - 10} ä¸ªé”®")

            # åŒæ­¥å˜æ›´çš„é”®
            logger.info("å¼€å§‹åŒæ­¥å˜æ›´çš„é”®...")
            sync_result = self._sync_changed_keys(changed_keys)

            logger.info(f"âœ“ åŒæ­¥å®Œæˆ:")
            logger.info(f"  æˆåŠŸ: {sync_result['synced']} ä¸ª")
            logger.info(f"  å¤±è´¥: {sync_result['failed']} ä¸ª")

            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self.incremental_stats['total_changes'] += len(changed_keys)
            self.incremental_stats['successful_changes'] += sync_result['synced']
            self.incremental_stats['failed_changes'] += sync_result['failed']
            self.incremental_stats['last_sync_time'] = datetime.now()

            duration = time.time() - start_time
            self.incremental_stats['sync_intervals'].append(duration)

            # æ›´æ–°æœ€ååŒæ­¥æ—¶é—´
            self.last_sync_time = start_time

            logger.info(f"âœ“ å¢é‡åŒæ­¥å®Œæˆï¼Œè€—æ—¶: {duration:.2f} ç§’")
            logger.info("=" * 60)

            return {
                'success': True,
                'changed_keys': len(changed_keys),
                'synced_keys': sync_result['synced'],
                'failed_keys': sync_result['failed'],
                'duration': duration,
                'sync_timestamp': start_time
            }

        except Exception as e:
            logger.error(f"âœ— å¢é‡åŒæ­¥å¤±è´¥: {e}", exc_info=True)
            logger.info("=" * 60)
            return {
                'success': False,
                'error': str(e),
                'duration': time.time() - start_time
            }
    
    def _incremental_sync_worker(self,
                                sync_interval: int,
                                key_pattern: str,
                                key_types: Optional[List[str]],
                                change_callback: Optional[Callable],
                                max_changes_per_sync: int):
        """å¢é‡åŒæ­¥å·¥ä½œçº¿ç¨‹ã€‚"""
        logger.info("å¢é‡åŒæ­¥å·¥ä½œçº¿ç¨‹å¯åŠ¨")
        
        while not self.stop_event.is_set():
            try:
                # æ‰§è¡Œå¢é‡åŒæ­¥
                result = self.perform_incremental_sync(
                    key_pattern, key_types, None, max_changes_per_sync
                )
                
                # è°ƒç”¨å˜æ›´å›è°ƒ
                if change_callback and result['success']:
                    try:
                        change_callback(result)
                    except Exception as e:
                        logger.error(f"å˜æ›´å›è°ƒæ‰§è¡Œå¤±è´¥: {e}")
                
                # ç­‰å¾…ä¸‹æ¬¡åŒæ­¥
                self.stop_event.wait(sync_interval)
                
            except Exception as e:
                logger.error(f"å¢é‡åŒæ­¥å·¥ä½œçº¿ç¨‹å‡ºé”™: {e}")
                self.stop_event.wait(sync_interval)
        
        logger.info("å¢é‡åŒæ­¥å·¥ä½œçº¿ç¨‹åœæ­¢")
    
    def _detect_changed_keys(self,
                           key_pattern: str,
                           key_types: Optional[List[str]],
                           since_timestamp: float,
                           max_changes: int) -> List[str]:
        """
        æ£€æµ‹å˜æ›´çš„é”®ã€‚

        è¿™é‡Œä½¿ç”¨å¤šç§ç­–ç•¥æ¥æ£€æµ‹å˜æ›´ï¼š
        1. æ¯”è¾ƒé”®çš„æœ€åä¿®æ”¹æ—¶é—´ï¼ˆå¦‚æœRedisæ”¯æŒï¼‰
        2. æ¯”è¾ƒé”®çš„å€¼å“ˆå¸Œ
        3. æ‰«ææ‰€æœ‰é”®å¹¶ä¸ç›®æ ‡æ¯”è¾ƒ
        """
        changed_keys = []

        try:
            logger.info("ç­–ç•¥1: ä½¿ç”¨OBJECT IDLETIMEæ£€æµ‹æœ€è¿‘æ´»è·ƒçš„é”®")
            # ç­–ç•¥1: ä½¿ç”¨OBJECT IDLETIMEæ£€æµ‹æœ€è¿‘æ´»è·ƒçš„é”®
            idle_changes = self._detect_changes_by_idle_time(
                key_pattern, key_types, since_timestamp, max_changes
            )
            changed_keys.extend(idle_changes)
            logger.info(f"  ç©ºé—²æ—¶é—´æ£€æµ‹åˆ° {len(idle_changes)} ä¸ªå˜æ›´")

            # å¦‚æœæ£€æµ‹åˆ°çš„å˜æ›´ä¸å¤Ÿï¼Œä½¿ç”¨ç­–ç•¥2: å€¼æ¯”è¾ƒ
            if len(changed_keys) < max_changes:
                logger.info("ç­–ç•¥2: ä½¿ç”¨å€¼æ¯”è¾ƒæ£€æµ‹å˜æ›´")
                remaining_limit = max_changes - len(changed_keys)
                additional_changes = self._detect_changes_by_comparison(
                    key_pattern, key_types, remaining_limit, set(changed_keys)
                )
                changed_keys.extend(additional_changes)
                logger.info(f"  å€¼æ¯”è¾ƒæ£€æµ‹åˆ° {len(additional_changes)} ä¸ªé¢å¤–å˜æ›´")

            logger.info(f"æ€»å…±æ£€æµ‹åˆ° {len(changed_keys)} ä¸ªå˜æ›´çš„é”®")
            return changed_keys[:max_changes]

        except Exception as e:
            logger.error(f"âœ— æ£€æµ‹é”®å˜æ›´å¤±è´¥: {e}", exc_info=True)
            return []
    
    def _detect_changes_by_idle_time(self,
                                   key_pattern: str,
                                   key_types: Optional[List[str]],
                                   since_timestamp: float,
                                   max_changes: int) -> List[str]:
        """
        é€šè¿‡ç©ºé—²æ—¶é—´æ£€æµ‹å˜æ›´çš„é”®ï¼ˆä½¿ç”¨SCANé¿å…é˜»å¡ + Pipelineæ‰¹é‡æ£€æµ‹ï¼‰

        OBJECT IDLETIMEè¿”å›é”®è‡ªä¸Šæ¬¡è®¿é—®ä»¥æ¥çš„ç§’æ•°ã€‚
        å¦‚æœidle_timeå°ï¼Œè¯´æ˜æœ€è¿‘è¢«è®¿é—®/ä¿®æ”¹è¿‡ã€‚

        æ³¨æ„ï¼šä½¿ç”¨SCANè€Œä¸æ˜¯KEYSï¼Œé¿å…åœ¨å¤§æ•°æ®é‡æ—¶é˜»å¡Redis
        """
        changed_keys = []
        current_time = time.time()
        # è®¡ç®—æ—¶é—´å·®ï¼ˆç§’ï¼‰
        time_diff = current_time - since_timestamp

        logger.debug(f"ğŸ” æ£€æµ‹å˜æ›´ï¼šæ—¶é—´å·®={time_diff:.1f}ç§’")

        try:
            # ä½¿ç”¨SCANè¿­ä»£æ‰€æœ‰é”®ï¼ˆé¿å…é˜»å¡ï¼‰
            all_keys = []
            cursor = 0
            scan_count = 1000  # æ¯æ¬¡SCANè¿”å›çš„é”®æ•°

            while True:
                cursor, keys = self.source_client.scan(
                    cursor=cursor,
                    match=key_pattern,
                    count=scan_count
                )
                all_keys.extend(keys)

                if cursor == 0:
                    break

            if not all_keys:
                return []

            logger.debug(f"ğŸ“Š SCANè·å–åˆ° {len(all_keys)} ä¸ªé”®")

            # ä¼˜åŒ–1ï¼šä½¿ç”¨Pipelineæ‰¹é‡æ£€æŸ¥ç±»å‹ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if key_types:
                pipe = self.source_client.pipeline(transaction=False)
                for key in all_keys:
                    pipe.type(key)

                types = pipe.execute()

                # è¿‡æ»¤åŒ¹é…çš„é”®
                filtered_keys = []
                for i, key_type in enumerate(types):
                    if isinstance(key_type, bytes):
                        key_type = key_type.decode()
                    if key_type in key_types:
                        filtered_keys.append(all_keys[i])

                all_keys = filtered_keys
                logger.debug(f"ğŸ“Š ç±»å‹è¿‡æ»¤å: {len(all_keys)} ä¸ªé”®")

            if not all_keys:
                return []

            # ä¼˜åŒ–2ï¼šä½¿ç”¨Pipelineæ‰¹é‡æ£€æŸ¥IDLETIME
            # åˆ†æ‰¹å¤„ç†ï¼Œé¿å…å•æ¬¡Pipelineè¿‡å¤§
            batch_size = 1000
            for batch_start in range(0, len(all_keys), batch_size):
                batch_keys = all_keys[batch_start:batch_start + batch_size]

                pipe = self.source_client.pipeline(transaction=False)
                for key in batch_keys:
                    pipe.object('idletime', key)

                idle_times = pipe.execute()

                # æ£€æŸ¥å“ªäº›é”®å˜æ›´äº†
                for i, idle_time in enumerate(idle_times):
                    if idle_time is not None:
                        # idle_timeæ˜¯é”®è‡ªä¸Šæ¬¡è®¿é—®ä»¥æ¥çš„ç§’æ•°
                        # å¦‚æœidle_time <= time_diffï¼Œè¯´æ˜åœ¨ä¸Šæ¬¡åŒæ­¥ä¹‹åæœ‰æ´»åŠ¨
                        if idle_time <= time_diff + 5:  # åŠ 5ç§’å®¹é”™
                            key = batch_keys[i]
                            key_str = key.decode() if isinstance(key, bytes) else key
                            changed_keys.append(key_str)
                            logger.debug(f"âœ“ å˜æ›´é”®: {key_str}, idle={idle_time}ç§’")

                            if len(changed_keys) >= max_changes:
                                break

                if len(changed_keys) >= max_changes:
                    break

            logger.info(f"âœ… æ£€æµ‹åˆ° {len(changed_keys)} ä¸ªå˜æ›´é”®ï¼ˆæ€»å…±{len(all_keys)}ä¸ªé”®ï¼‰")
            return changed_keys

        except Exception as e:
            logger.error(f"âŒ æ£€æµ‹å˜æ›´å¤±è´¥: {e}", exc_info=True)
            return []
    
    def _detect_changes_by_comparison(self,
                                    key_pattern: str,
                                    key_types: Optional[List[str]],
                                    max_changes: int,
                                    exclude_keys: Set[str]) -> List[str]:
        """
        é€šè¿‡å€¼æ¯”è¾ƒæ£€æµ‹å˜æ›´çš„é”®ã€‚

        è¿™ä¸ªæ–¹æ³•ä¼šæ‰«ææ‰€æœ‰åŒ¹é…çš„é”®ï¼Œå¹¶æ¯”è¾ƒæºå’Œç›®æ ‡çš„å€¼ã€‚
        å¦‚æœé”®ä¸å­˜åœ¨äºç›®æ ‡æˆ–å€¼ä¸åŒï¼Œåˆ™è®¤ä¸ºæ˜¯å˜æ›´ã€‚
        """
        changed_keys = []

        cursor = 0
        scanned_count = 0

        logger.debug(f"å¼€å§‹å€¼æ¯”è¾ƒæ£€æµ‹ï¼Œæ’é™¤é”®æ•°: {len(exclude_keys)}")

        while len(changed_keys) < max_changes and scanned_count < 50000:
            try:
                cursor, keys = self.source_client.scan(
                    cursor=cursor,
                    match=key_pattern,
                    count=self.scan_count // 2  # æ¯”è¾ƒæ¨¡å¼ä½¿ç”¨è¾ƒå°çš„count
                )

                for key in keys:
                    scanned_count += 1
                    key_str = key.decode() if isinstance(key, bytes) else key

                    # è·³è¿‡å·²ç»æ£€æµ‹è¿‡çš„é”®
                    if key_str in exclude_keys:
                        continue

                    try:
                        # æ£€æŸ¥é”®ç±»å‹
                        if key_types:
                            key_type = self.source_client.type(key)
                            if isinstance(key_type, bytes):
                                key_type = key_type.decode()
                            if key_type not in key_types:
                                continue

                        # æ¯”è¾ƒæºå’Œç›®æ ‡çš„å€¼
                        is_different, reason = self._is_key_different(key)
                        if is_different:
                            changed_keys.append(key_str)
                            logger.debug(f"æ£€æµ‹åˆ°å˜æ›´é”®: {key_str}, åŸå› : {reason}")

                            if len(changed_keys) >= max_changes:
                                break

                    except Exception as e:
                        logger.debug(f"æ¯”è¾ƒé”® {key} å¤±è´¥: {e}")
                        continue

                if cursor == 0:
                    break

            except Exception as e:
                logger.error(f"æ¯”è¾ƒæ‰«ææ—¶å‡ºé”™: {e}")
                break

        logger.info(f"é€šè¿‡å€¼æ¯”è¾ƒæ£€æµ‹åˆ° {len(changed_keys)} ä¸ªå˜æ›´çš„é”®ï¼ˆæ‰«æäº†{scanned_count}ä¸ªé”®ï¼‰")
        return changed_keys
    
    def _is_key_different(self, key) -> tuple:
        """
        æ£€æŸ¥é”®åœ¨æºå’Œç›®æ ‡ä¸­æ˜¯å¦ä¸åŒã€‚

        è¿”å›:
            (is_different, reason): æ˜¯å¦ä¸åŒå’ŒåŸå› 
        """
        try:
            # æ£€æŸ¥é”®æ˜¯å¦å­˜åœ¨äºç›®æ ‡
            if not self.target_client.exists(key):
                return (True, "ç›®æ ‡ä¸­ä¸å­˜åœ¨")

            # æ£€æŸ¥ç±»å‹æ˜¯å¦ç›¸åŒ
            source_type = self.source_client.type(key)
            target_type = self.target_client.type(key)

            if isinstance(source_type, bytes):
                source_type = source_type.decode()
            if isinstance(target_type, bytes):
                target_type = target_type.decode()

            if source_type != target_type:
                return (True, f"ç±»å‹ä¸åŒ: {source_type} vs {target_type}")

            # æ ¹æ®ç±»å‹æ¯”è¾ƒå€¼
            if source_type == 'string':
                source_val = self.source_client.get(key)
                target_val = self.target_client.get(key)
                if source_val != target_val:
                    return (True, "å€¼ä¸åŒ")

            elif source_type == 'hash':
                source_hash = self.source_client.hgetall(key)
                target_hash = self.target_client.hgetall(key)
                if source_hash != target_hash:
                    return (True, "å“ˆå¸Œå€¼ä¸åŒ")

            elif source_type == 'list':
                source_list = self.source_client.lrange(key, 0, -1)
                target_list = self.target_client.lrange(key, 0, -1)
                if source_list != target_list:
                    return (True, "åˆ—è¡¨å€¼ä¸åŒ")

            elif source_type == 'set':
                source_set = self.source_client.smembers(key)
                target_set = self.target_client.smembers(key)
                if source_set != target_set:
                    return (True, "é›†åˆå€¼ä¸åŒ")

            elif source_type == 'zset':
                source_zset = self.source_client.zrange(key, 0, -1, withscores=True)
                target_zset = self.target_client.zrange(key, 0, -1, withscores=True)
                if source_zset != target_zset:
                    return (True, "æœ‰åºé›†åˆå€¼ä¸åŒ")

            else:
                # å¯¹äºå…¶ä»–ç±»å‹ï¼Œå‡è®¾ä¸åŒ
                return (True, f"æœªçŸ¥ç±»å‹: {source_type}")

            # å€¼ç›¸åŒ
            return (False, "å€¼ç›¸åŒ")

        except Exception as e:
            logger.debug(f"æ¯”è¾ƒé”® {key} æ—¶å‡ºé”™: {e}")
            return (True, f"æ¯”è¾ƒå‡ºé”™: {str(e)}")  # å‡ºé”™æ—¶å‡è®¾ä¸åŒï¼Œéœ€è¦åŒæ­¥
    
    def _sync_changed_keys(self, changed_keys: List[str]) -> Dict[str, int]:
        """åŒæ­¥å˜æ›´çš„é”®ã€‚"""
        synced_count = 0
        failed_count = 0

        logger.info(f"å¼€å§‹åŒæ­¥ {len(changed_keys)} ä¸ªå˜æ›´çš„é”®")

        for i, key in enumerate(changed_keys, 1):
            try:
                logger.debug(f"  [{i}/{len(changed_keys)}] åŒæ­¥é”®: {key}")
                if self._sync_single_key(key):
                    synced_count += 1
                    logger.debug(f"    âœ“ åŒæ­¥æˆåŠŸ")
                else:
                    failed_count += 1
                    logger.warning(f"    âœ— åŒæ­¥å¤±è´¥")
            except Exception as e:
                logger.error(f"    âœ— åŒæ­¥é”® {key} å¤±è´¥: {e}", exc_info=True)
                failed_count += 1

        logger.info(f"åŒæ­¥å®Œæˆ: æˆåŠŸ {synced_count}, å¤±è´¥ {failed_count}")
        return {'synced': synced_count, 'failed': failed_count}
    
    def _sync_single_key(self, key: str) -> bool:
        """åŒæ­¥å•ä¸ªé”®ã€‚"""
        try:
            # æ£€æŸ¥æºé”®æ˜¯å¦å­˜åœ¨
            if not self.source_client.exists(key):
                logger.debug(f"      æºé”®ä¸å­˜åœ¨ï¼Œåˆ é™¤ç›®æ ‡é”®: {key}")
                # å¦‚æœæºé”®ä¸å­˜åœ¨ï¼Œåˆ é™¤ç›®æ ‡é”®
                self.target_client.delete(key)
                self.incremental_stats['change_types']['deleted'] += 1
                return True

            # è·å–é”®ç±»å‹å’ŒTTL
            key_type = self.source_client.type(key)
            if isinstance(key_type, bytes):
                key_type = key_type.decode()
            ttl = self.source_client.ttl(key)

            logger.debug(f"      é”®ç±»å‹: {key_type}, TTL: {ttl}")

            # æ ¹æ®ç±»å‹åŒæ­¥æ•°æ®
            if key_type == 'string':
                value = self.source_client.get(key)
                logger.debug(f"      åŒæ­¥å­—ç¬¦ä¸²å€¼: {value[:50] if value and len(str(value)) > 50 else value}...")
                self.target_client.set(key, value)

            elif key_type == 'hash':
                values = self.source_client.hgetall(key)
                logger.debug(f"      åŒæ­¥å“ˆå¸Œï¼Œå­—æ®µæ•°: {len(values)}")
                self.target_client.delete(key)
                if values:
                    self.target_client.hset(key, mapping=values)

            elif key_type == 'list':
                values = self.source_client.lrange(key, 0, -1)
                logger.debug(f"      åŒæ­¥åˆ—è¡¨ï¼Œå…ƒç´ æ•°: {len(values)}")
                self.target_client.delete(key)
                if values:
                    self.target_client.lpush(key, *reversed(values))

            elif key_type == 'set':
                values = self.source_client.smembers(key)
                logger.debug(f"      åŒæ­¥é›†åˆï¼Œæˆå‘˜æ•°: {len(values)}")
                self.target_client.delete(key)
                if values:
                    self.target_client.sadd(key, *values)

            elif key_type == 'zset':
                values = self.source_client.zrange(key, 0, -1, withscores=True)
                logger.debug(f"      åŒæ­¥æœ‰åºé›†åˆï¼Œæˆå‘˜æ•°: {len(values)}")
                self.target_client.delete(key)
                if values:
                    self.target_client.zadd(key, dict(values))

            elif key_type == 'stream':
                logger.debug(f"      åŒæ­¥æµç±»å‹")
                # å¯¹äºæµç±»å‹ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
                self._sync_stream_key(key)

            else:
                logger.warning(f"      ä¸æ”¯æŒçš„é”®ç±»å‹: {key_type}")
                return False

            # è®¾ç½®TTL
            if ttl > 0:
                self.target_client.expire(key, ttl)
                logger.debug(f"      è®¾ç½®TTL: {ttl}ç§’")

            self.incremental_stats['change_types']['updated'] += 1

            # éªŒè¯åŒæ­¥ç»“æœ
            if key_type == 'string':
                target_value = self.target_client.get(key)
                source_value = self.source_client.get(key)
                if target_value == source_value:
                    logger.debug(f"      âœ“ éªŒè¯æˆåŠŸ: å€¼å·²åŒæ­¥")
                else:
                    logger.warning(f"      âœ— éªŒè¯å¤±è´¥: æºå€¼={source_value}, ç›®æ ‡å€¼={target_value}")

            return True

        except Exception as e:
            logger.error(f"      âœ— åŒæ­¥é”® {key} å¤±è´¥: {e}", exc_info=True)
            return False
    
    def _sync_stream_key(self, key: str):
        """åŒæ­¥æµç±»å‹çš„é”®ã€‚"""
        try:
            # è·å–ç›®æ ‡æµçš„æœ€åID
            target_info = self.target_client.xinfo_stream(key)
            last_id = target_info.get('last-generated-id', '0-0')
        except:
            # å¦‚æœç›®æ ‡æµä¸å­˜åœ¨ï¼Œä»å¤´å¼€å§‹
            last_id = '0-0'
            self.target_client.delete(key)
        
        # è·å–æºæµä¸­æ–°çš„æ¡ç›®
        try:
            entries = self.source_client.xrange(key, min=f"({last_id}")
            for entry_id, fields in entries:
                self.target_client.xadd(key, fields, id=entry_id)
        except Exception as e:
            logger.error(f"åŒæ­¥æµé”® {key} å¤±è´¥: {e}")
            raise
    
    def get_incremental_stats(self) -> Dict[str, Any]:
        """è·å–å¢é‡è¿ç§»ç»Ÿè®¡ä¿¡æ¯ã€‚"""
        stats = self.incremental_stats.copy()
        
        if stats['start_time']:
            stats['running_time'] = datetime.now() - stats['start_time']
            stats['running_time_seconds'] = stats['running_time'].total_seconds()
        
        if stats['sync_intervals']:
            stats['avg_sync_duration'] = sum(stats['sync_intervals']) / len(stats['sync_intervals'])
            stats['total_syncs'] = len(stats['sync_intervals'])
        
        stats['is_monitoring'] = self.is_monitoring
        stats['last_sync_timestamp'] = self.last_sync_time
        
        return stats
    
    def set_sync_checkpoint(self, checkpoint_data: Dict[str, Any]):
        """è®¾ç½®åŒæ­¥æ£€æŸ¥ç‚¹ã€‚"""
        self.sync_checkpoint = checkpoint_data
        self.last_sync_time = checkpoint_data.get('timestamp', time.time())
        logger.info(f"è®¾ç½®åŒæ­¥æ£€æŸ¥ç‚¹: {checkpoint_data}")
    
    def get_sync_checkpoint(self) -> Dict[str, Any]:
        """è·å–åŒæ­¥æ£€æŸ¥ç‚¹ã€‚"""
        return {
            'timestamp': self.last_sync_time,
            'checkpoint_data': self.sync_checkpoint,
            'stats': self.get_incremental_stats()
        }
