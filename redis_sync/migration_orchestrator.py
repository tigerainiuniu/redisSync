"""
Redisè¿ç§»ç¼–æ’å™¨

åè°ƒä¸åŒè¿ç§»ç­–ç•¥ï¼ˆåŒ…æ‹¬SYNCã€SCANå’ŒREPLCONFï¼‰çš„ä¸»è¦ç±»ã€‚
ä¸ºRedisæ•°æ®è¿ç§»å’ŒåŒæ­¥æä¾›ç»Ÿä¸€æ¥å£ã€‚
"""

import redis
import logging
import time
import threading
from enum import Enum
from typing import Optional, Dict, Any, Callable, List
from dataclasses import dataclass

from .connection_manager import RedisConnectionManager
from .sync_handler import SyncHandler
from .scan_handler import ScanHandler
from .replconf_handler import ReplConfHandler
from .full_migration_handler import FullMigrationHandler
from .incremental_migration_handler import IncrementalMigrationHandler
from .exceptions import MigrationError, ConfigurationError

logger = logging.getLogger(__name__)


class MigrationStrategy(Enum):
    """è¿ç§»ç­–ç•¥é€‰é¡¹ã€‚"""
    SCAN = "scan"
    SYNC = "sync"
    PSYNC = "psync"
    HYBRID = "hybrid"
    FULL = "full"  # å…¨é‡è¿ç§»
    INCREMENTAL = "incremental"  # å¢é‡è¿ç§»


class MigrationType(Enum):
    """è¿ç§»ç±»å‹ã€‚"""
    FULL = "full"  # å…¨é‡è¿ç§»
    INCREMENTAL = "incremental"  # å¢é‡è¿ç§»


@dataclass
class MigrationConfig:
    """è¿ç§»æ“ä½œçš„é…ç½®ã€‚"""
    strategy: MigrationStrategy = MigrationStrategy.SCAN
    migration_type: MigrationType = MigrationType.FULL
    batch_size: int = 100
    scan_count: int = 1000
    preserve_ttl: bool = True
    overwrite_existing: bool = False
    key_pattern: str = "*"
    key_type: Optional[str] = None
    key_types: Optional[List[str]] = None  # æ”¯æŒå¤šç§é”®ç±»å‹
    enable_replication: bool = False
    replication_port: int = 6380
    replication_timeout: int = 30
    progress_callback: Optional[Callable[[int, int], None]] = None
    verify_migration: bool = True
    verify_mode: str = "fast"  # éªŒè¯æ¨¡å¼: fastï¼ˆå¿«é€Ÿï¼‰, fullï¼ˆå®Œæ•´ï¼‰
    verify_sample_size: Optional[int] = 100  # éªŒè¯é‡‡æ ·æ•°é‡
    max_retries: int = 3
    retry_delay: float = 1.0

    # å…¨é‡è¿ç§»ç‰¹å®šé…ç½®
    clear_target: bool = False  # æ˜¯å¦æ¸…ç©ºç›®æ ‡æ•°æ®åº“
    full_strategy: str = "scan"  # å…¨é‡è¿ç§»å­ç­–ç•¥: scan, sync, dump_restore

    # å¢é‡è¿ç§»ç‰¹å®šé…ç½®
    sync_interval: int = 60  # å¢é‡åŒæ­¥é—´éš”ï¼ˆç§’ï¼‰
    max_changes_per_sync: int = 10000  # æ¯æ¬¡åŒæ­¥çš„æœ€å¤§å˜æ›´æ•°
    since_timestamp: Optional[float] = None  # èµ·å§‹æ—¶é—´æˆ³
    change_callback: Optional[Callable] = None  # å˜æ›´å›è°ƒå‡½æ•°
    continuous_sync: bool = False  # æ˜¯å¦å¯ç”¨æŒç»­åŒæ­¥


class MigrationOrchestrator:
    """ä½¿ç”¨å„ç§ç­–ç•¥ç¼–æ’Redisè¿ç§»ã€‚"""

    def __init__(self, connection_manager: RedisConnectionManager):
        """
        åˆå§‹åŒ–è¿ç§»ç¼–æ’å™¨ã€‚

        å‚æ•°:
            connection_manager: Redisè¿æ¥ç®¡ç†å™¨å®ä¾‹
        """
        self.connection_manager = connection_manager
        self.sync_handler: Optional[SyncHandler] = None
        self.scan_handler: Optional[ScanHandler] = None
        self.replconf_handler: Optional[ReplConfHandler] = None
        self.full_migration_handler: Optional[FullMigrationHandler] = None
        self.incremental_migration_handler: Optional[IncrementalMigrationHandler] = None
        self._stop_replication = threading.Event()
        self._replication_thread: Optional[threading.Thread] = None
        
    def initialize_handlers(self):
        """åˆå§‹åŒ–è¿ç§»å¤„ç†å™¨ã€‚"""
        if not self.connection_manager.source_client or not self.connection_manager.target_client:
            raise RuntimeError("æºå’Œç›®æ ‡Rediså®¢æˆ·ç«¯å¿…é¡»å·²è¿æ¥")

        self.sync_handler = SyncHandler(
            self.connection_manager.source_client,
            self.connection_manager.target_client
        )

        self.scan_handler = ScanHandler(
            self.connection_manager.source_client,
            self.connection_manager.target_client
        )

        self.replconf_handler = ReplConfHandler(
            self.connection_manager.source_client,
            self.connection_manager.target_client
        )

        self.full_migration_handler = FullMigrationHandler(
            self.connection_manager.source_client,
            self.connection_manager.target_client
        )

        self.incremental_migration_handler = IncrementalMigrationHandler(
            self.connection_manager.source_client,
            self.connection_manager.target_client
        )

        logger.info("è¿ç§»å¤„ç†å™¨å·²åˆå§‹åŒ–")

    def initialize_handlers_with_config(self, scan_count: int = 10000):
        """åˆå§‹åŒ–è¿ç§»å¤„ç†å™¨ï¼ˆå¸¦é…ç½®ï¼‰ã€‚"""
        if not self.connection_manager.source_client or not self.connection_manager.target_client:
            raise RuntimeError("æºå’Œç›®æ ‡Rediså®¢æˆ·ç«¯å¿…é¡»å·²è¿æ¥")

        self.sync_handler = SyncHandler(
            self.connection_manager.source_client,
            self.connection_manager.target_client
        )

        self.scan_handler = ScanHandler(
            self.connection_manager.source_client,
            self.connection_manager.target_client
        )

        self.replconf_handler = ReplConfHandler(
            self.connection_manager.source_client,
            self.connection_manager.target_client
        )

        self.full_migration_handler = FullMigrationHandler(
            self.connection_manager.source_client,
            self.connection_manager.target_client
        )

        self.incremental_migration_handler = IncrementalMigrationHandler(
            self.connection_manager.source_client,
            self.connection_manager.target_client,
            scan_count=scan_count  # ä¼ é€’scan_counté…ç½®
        )

        logger.info(f"è¿ç§»å¤„ç†å™¨å·²åˆå§‹åŒ–ï¼ˆscan_count={scan_count}ï¼‰")
    
    def migrate(self, config: MigrationConfig) -> Dict[str, Any]:
        """
        æ ¹æ®é…ç½®æ‰§è¡Œè¿ç§»ã€‚

        å‚æ•°:
            config: è¿ç§»é…ç½®

        è¿”å›:
            è¿ç§»ç»“æœå’Œç»Ÿè®¡ä¿¡æ¯
        """
        if not self.sync_handler or not self.scan_handler or not self.replconf_handler:
            self.initialize_handlers()

        logger.info(f"å¼€å§‹è¿ç§»ï¼Œç­–ç•¥: {config.strategy.value}ï¼Œç±»å‹: {config.migration_type.value}")

        start_time = time.time()
        results = {
            'strategy': config.strategy.value,
            'migration_type': config.migration_type.value,
            'start_time': start_time,
            'end_time': None,
            'duration': None,
            'success': False,
            'statistics': {},
            'errors': []
        }

        try:
            # æ ¹æ®è¿ç§»ç±»å‹é€‰æ‹©å¤„ç†æ–¹å¼
            if config.migration_type == MigrationType.FULL:
                results['statistics'] = self._perform_full_migration(config)
            elif config.migration_type == MigrationType.INCREMENTAL:
                results['statistics'] = self._perform_incremental_migration(config)
            else:
                # å…¼å®¹æ—§çš„ç­–ç•¥æ–¹å¼
                if config.strategy == MigrationStrategy.SCAN:
                    results['statistics'] = self._migrate_with_scan(config)
                elif config.strategy == MigrationStrategy.SYNC:
                    results['statistics'] = self._migrate_with_sync(config)
                elif config.strategy == MigrationStrategy.PSYNC:
                    results['statistics'] = self._migrate_with_psync(config)
                elif config.strategy == MigrationStrategy.HYBRID:
                    results['statistics'] = self._migrate_with_hybrid(config)
                elif config.strategy == MigrationStrategy.FULL:
                    results['statistics'] = self._perform_full_migration(config)
                elif config.strategy == MigrationStrategy.INCREMENTAL:
                    results['statistics'] = self._perform_incremental_migration(config)
                else:
                    raise ValueError(f"ä¸æ”¯æŒçš„è¿ç§»ç­–ç•¥: {config.strategy}")

            # å¦‚æœéœ€è¦ï¼ŒéªŒè¯è¿ç§»
            if config.verify_migration and config.migration_type == MigrationType.FULL:
                verify_start = time.time()
                logger.info("ğŸ” å¼€å§‹éªŒè¯è¿ç§»...")
                verification_results = self._verify_migration(config)
                verify_elapsed = time.time() - verify_start
                results['verification'] = verification_results
                results['verification_time'] = verify_elapsed

                if verification_results.get('success', False):
                    logger.info(f"âœ… è¿ç§»éªŒè¯é€šè¿‡ (è€—æ—¶: {verify_elapsed:.2f}ç§’)")
                else:
                    logger.warning(f"âš ï¸  è¿ç§»éªŒè¯å¤±è´¥ (è€—æ—¶: {verify_elapsed:.2f}ç§’)")

            results['success'] = True
            logger.info("è¿ç§»æˆåŠŸå®Œæˆ")
            
        except Exception as e:
            error_msg = f"Migration failed: {e}"
            logger.error(error_msg)
            results['errors'].append(error_msg)
            results['success'] = False
        
        finally:
            end_time = time.time()
            results['end_time'] = end_time
            results['duration'] = end_time - start_time
            
            # Stop replication if running
            if self._replication_thread and self._replication_thread.is_alive():
                self.stop_replication()
        
        return results

    def _perform_full_migration(self, config: MigrationConfig) -> Dict[str, Any]:
        """æ‰§è¡Œå…¨é‡è¿ç§»ã€‚"""
        if not self.full_migration_handler:
            raise RuntimeError("å…¨é‡è¿ç§»å¤„ç†å™¨æœªåˆå§‹åŒ–")

        logger.info(f"å¼€å§‹å…¨é‡è¿ç§»ï¼Œå­ç­–ç•¥: {config.full_strategy}")

        # å‡†å¤‡é”®ç±»å‹åˆ—è¡¨
        key_types = None
        if config.key_type:
            key_types = [config.key_type]
        elif config.key_types:
            key_types = config.key_types

        result = self.full_migration_handler.perform_full_migration(
            strategy=config.full_strategy,
            clear_target=config.clear_target,
            preserve_ttl=config.preserve_ttl,
            batch_size=config.batch_size,
            scan_count=config.scan_count,
            progress_callback=config.progress_callback,
            key_pattern=config.key_pattern,
            key_types=key_types
        )

        return result.get('statistics', {})

    def _perform_incremental_migration(self, config: MigrationConfig) -> Dict[str, Any]:
        """æ‰§è¡Œå¢é‡è¿ç§»ã€‚"""
        if not self.incremental_migration_handler:
            raise RuntimeError("å¢é‡è¿ç§»å¤„ç†å™¨æœªåˆå§‹åŒ–")

        logger.info("å¼€å§‹å¢é‡è¿ç§»")

        # å‡†å¤‡é”®ç±»å‹åˆ—è¡¨
        key_types = None
        if config.key_type:
            key_types = [config.key_type]
        elif config.key_types:
            key_types = config.key_types

        if config.continuous_sync:
            # å¯åŠ¨æŒç»­å¢é‡åŒæ­¥
            success = self.incremental_migration_handler.start_incremental_sync(
                sync_interval=config.sync_interval,
                key_pattern=config.key_pattern,
                key_types=key_types,
                change_callback=config.change_callback,
                max_changes_per_sync=config.max_changes_per_sync
            )

            return {
                'continuous_sync_started': success,
                'sync_interval': config.sync_interval,
                'max_changes_per_sync': config.max_changes_per_sync
            }
        else:
            # æ‰§è¡Œä¸€æ¬¡æ€§å¢é‡åŒæ­¥
            result = self.incremental_migration_handler.perform_incremental_sync(
                key_pattern=config.key_pattern,
                key_types=key_types,
                since_timestamp=config.since_timestamp,
                max_changes=config.max_changes_per_sync
            )

            return result

    def _migrate_with_scan(self, config: MigrationConfig) -> Dict[str, Any]:
        """Migrate using SCAN strategy."""
        logger.info("Performing SCAN-based migration")
        
        return self.scan_handler.migrate_all_keys(
            pattern=config.key_pattern,
            key_type=config.key_type,
            batch_size=config.batch_size,
            scan_count=config.scan_count,
            preserve_ttl=config.preserve_ttl,
            overwrite=config.overwrite_existing,
            progress_callback=config.progress_callback
        )
    
    def _migrate_with_sync(self, config: MigrationConfig) -> Dict[str, Any]:
        """Migrate using SYNC strategy."""
        logger.info("Performing SYNC-based migration")
        
        # Perform replication handshake if enabled
        if config.enable_replication:
            success = self.replconf_handler.perform_replication_handshake(
                listening_port=config.replication_port
            )
            if not success:
                raise RuntimeError("Replication handshake failed")
        
        # Perform full sync
        success = self.sync_handler.perform_full_sync(
            progress_callback=config.progress_callback
        )
        
        if not success:
            raise RuntimeError("Full synchronization failed")
        
        # Start continuous replication if enabled
        if config.enable_replication:
            self._start_replication_stream(config)
        
        return {
            'sync_completed': True,
            'replication_enabled': config.enable_replication
        }
    
    def _migrate_with_psync(self, config: MigrationConfig) -> Dict[str, Any]:
        """Migrate using PSYNC strategy."""
        logger.info("Performing PSYNC-based migration")
        
        # Perform replication handshake
        if config.enable_replication:
            success = self.replconf_handler.perform_replication_handshake(
                listening_port=config.replication_port
            )
            if not success:
                raise RuntimeError("Replication handshake failed")
        
        # Attempt partial sync
        success = self.sync_handler.perform_psync(
            progress_callback=config.progress_callback
        )
        
        if not success:
            raise RuntimeError("Partial synchronization failed")
        
        # Start continuous replication if enabled
        if config.enable_replication:
            self._start_replication_stream(config)
        
        return {
            'psync_completed': True,
            'replication_enabled': config.enable_replication
        }
    
    def _migrate_with_hybrid(self, config: MigrationConfig) -> Dict[str, Any]:
        """Migrate using hybrid strategy (SYNC + SCAN for verification)."""
        logger.info("Performing hybrid migration (SYNC + SCAN verification)")
        
        results = {}
        
        # First, try SYNC migration
        try:
            sync_results = self._migrate_with_sync(config)
            results['sync_results'] = sync_results
        except Exception as e:
            logger.warning(f"SYNC migration failed, falling back to SCAN: {e}")
            scan_results = self._migrate_with_scan(config)
            results['scan_results'] = scan_results
            return results
        
        # Then, verify with SCAN comparison
        logger.info("Verifying SYNC migration with SCAN comparison")
        comparison_results = self.scan_handler.compare_keys(
            pattern=config.key_pattern,
            sample_size=10000  # Limit comparison for performance
        )
        results['comparison_results'] = comparison_results
        
        # If significant mismatches, perform SCAN migration for missing keys
        missing_ratio = comparison_results.get('missing_in_target', 0) / max(comparison_results.get('total_compared', 1), 1)
        if missing_ratio > 0.01:  # More than 1% missing
            logger.warning(f"Found {missing_ratio:.2%} missing keys, performing supplementary SCAN migration")
            scan_results = self._migrate_with_scan(config)
            results['supplementary_scan_results'] = scan_results
        
        return results
    
    def _start_replication_stream(self, config: MigrationConfig):
        """Start continuous replication stream."""
        def replication_worker():
            def handle_command(command: str, args: List[str]):
                try:
                    # Apply command to target Redis
                    if command.upper() in ['SET', 'DEL', 'EXPIRE', 'LPUSH', 'RPUSH', 'SADD', 'ZADD', 'HSET']:
                        # Execute command on target
                        self.connection_manager.target_client.execute_command(command, *args)
                        logger.debug(f"Replicated command: {command} {args}")
                except Exception as e:
                    logger.error(f"Failed to replicate command {command}: {e}")
            
            self.sync_handler.start_replication_stream(
                callback=handle_command,
                stop_event=self._stop_replication
            )
        
        self._replication_thread = threading.Thread(target=replication_worker, daemon=True)
        self._replication_thread.start()
        logger.info("Replication stream started")
    
    def stop_replication(self):
        """Stop continuous replication."""
        if self._replication_thread and self._replication_thread.is_alive():
            self._stop_replication.set()
            self._replication_thread.join(timeout=5)
            logger.info("Replication stream stopped")
    
    def _verify_migration(self, config: MigrationConfig) -> Dict[str, Any]:
        """Verify migration by comparing source and target."""
        try:
            # è·å–éªŒè¯é…ç½®ï¼ˆä»configæˆ–ä½¿ç”¨é»˜è®¤å€¼ï¼‰
            verify_mode = getattr(config, 'verify_mode', 'fast')
            sample_size = getattr(config, 'verify_sample_size', 100)

            # ç¡®å®šæ˜¯å¦ä½¿ç”¨å¿«é€Ÿæ¨¡å¼
            use_fast_mode = (verify_mode == 'fast')

            logger.info(f"éªŒè¯æ¨¡å¼: {verify_mode}, é‡‡æ ·æ•°é‡: {sample_size}")

            comparison_results = self.scan_handler.compare_keys(
                pattern=config.key_pattern,
                sample_size=sample_size,
                use_fast_mode=use_fast_mode
            )

            total_compared = comparison_results.get('total_compared', 0)
            matching_keys = comparison_results.get('matching_keys', 0)

            success_rate = matching_keys / max(total_compared, 1)
            verification_success = success_rate >= 0.95  # 95% success threshold

            return {
                'success': verification_success,
                'success_rate': success_rate,
                'total_compared': total_compared,
                'matching_keys': matching_keys,
                'mode': verify_mode,
                'details': comparison_results
            }

        except Exception as e:
            logger.error(f"Migration verification failed: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def get_migration_status(self) -> Dict[str, Any]:
        """Get current migration status."""
        status = {
            'replication_active': self._replication_thread and self._replication_thread.is_alive(),
            'source_connected': self.connection_manager.source_client is not None,
            'target_connected': self.connection_manager.target_client is not None,
        }
        
        if self.replconf_handler:
            status['replication_config'] = self.replconf_handler.get_current_config()
            status['replication_lag'] = self.replconf_handler.get_replication_lag()
        
        if self.connection_manager.source_client:
            status['source_info'] = self.connection_manager.get_source_info()
        
        if self.connection_manager.target_client:
            status['target_info'] = self.connection_manager.get_target_info()
        
        return status
    
    def start_incremental_sync(self, config: MigrationConfig) -> bool:
        """å¯åŠ¨å¢é‡åŒæ­¥ã€‚"""
        if not self.incremental_migration_handler:
            self.initialize_handlers()

        # å‡†å¤‡é”®ç±»å‹åˆ—è¡¨
        key_types = None
        if config.key_type:
            key_types = [config.key_type]
        elif config.key_types:
            key_types = config.key_types

        return self.incremental_migration_handler.start_incremental_sync(
            sync_interval=config.sync_interval,
            key_pattern=config.key_pattern,
            key_types=key_types,
            change_callback=config.change_callback,
            max_changes_per_sync=config.max_changes_per_sync
        )

    def stop_incremental_sync(self) -> Dict[str, Any]:
        """åœæ­¢å¢é‡åŒæ­¥ã€‚"""
        if not self.incremental_migration_handler:
            return {'error': 'å¢é‡è¿ç§»å¤„ç†å™¨æœªåˆå§‹åŒ–'}

        return self.incremental_migration_handler.stop_incremental_sync()

    def get_incremental_stats(self) -> Dict[str, Any]:
        """è·å–å¢é‡åŒæ­¥ç»Ÿè®¡ä¿¡æ¯ã€‚"""
        if not self.incremental_migration_handler:
            return {'error': 'å¢é‡è¿ç§»å¤„ç†å™¨æœªåˆå§‹åŒ–'}

        return self.incremental_migration_handler.get_incremental_stats()

    def get_full_migration_progress(self) -> Dict[str, Any]:
        """è·å–å…¨é‡è¿ç§»è¿›åº¦ã€‚"""
        if not self.full_migration_handler:
            return {'error': 'å…¨é‡è¿ç§»å¤„ç†å™¨æœªåˆå§‹åŒ–'}

        return self.full_migration_handler.get_migration_progress()

    def set_incremental_checkpoint(self, checkpoint_data: Dict[str, Any]):
        """è®¾ç½®å¢é‡åŒæ­¥æ£€æŸ¥ç‚¹ã€‚"""
        if not self.incremental_migration_handler:
            self.initialize_handlers()

        self.incremental_migration_handler.set_sync_checkpoint(checkpoint_data)

    def get_incremental_checkpoint(self) -> Dict[str, Any]:
        """è·å–å¢é‡åŒæ­¥æ£€æŸ¥ç‚¹ã€‚"""
        if not self.incremental_migration_handler:
            return {'error': 'å¢é‡è¿ç§»å¤„ç†å™¨æœªåˆå§‹åŒ–'}

        return self.incremental_migration_handler.get_sync_checkpoint()

    def cleanup(self):
        """æ¸…ç†èµ„æºã€‚"""
        # åœæ­¢å¢é‡åŒæ­¥
        if self.incremental_migration_handler:
            self.incremental_migration_handler.stop_incremental_sync()

        # åœæ­¢å¤åˆ¶
        self.stop_replication()

        # å…³é—­è¿æ¥
        self.connection_manager.close_connections()

        logger.info("è¿ç§»ç¼–æ’å™¨å·²æ¸…ç†")
